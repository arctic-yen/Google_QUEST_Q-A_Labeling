{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ../input/huggingface-transformers/sacremoses-master/sacremoses-master > /dev/null\n",
    "!pip install ../input/huggingface-transformers/transformers-master/transformers-master > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/roberta-base-tf2/merges.txt\n",
      "/kaggle/input/roberta-base-tf2/tf_model.h5\n",
      "/kaggle/input/roberta-base-tf2/config.json\n",
      "/kaggle/input/roberta-base-tf2/vocab.json\n",
      "/kaggle/input/bert-tensorflow/bert-base-cased-config.json\n",
      "/kaggle/input/bert-tensorflow/bert-large-uncased-config.json\n",
      "/kaggle/input/bert-tensorflow/bert-base-chinese-tf_model.h5\n",
      "/kaggle/input/bert-tensorflow/bert-large-cased-whole-word-masking-tf_model.h5\n",
      "/kaggle/input/bert-tensorflow/bert-large-uncased-whole-word-masking-finetuned-squad-config.json\n",
      "/kaggle/input/bert-tensorflow/bert-base-cased-finetuned-mrpc-config.json\n",
      "/kaggle/input/bert-tensorflow/bert-large-cased-whole-word-masking-finetuned-squad-tf_model.h5\n",
      "/kaggle/input/bert-tensorflow/bert-base-german-dbmdz-cased-config.json\n",
      "/kaggle/input/bert-tensorflow/bert-base-cased-tf_model.h5\n",
      "/kaggle/input/bert-tensorflow/bert-large-cased-tf_model.h5\n",
      "/kaggle/input/bert-tensorflow/bert-large-uncased-tf_model.h5\n",
      "/kaggle/input/bert-tensorflow/bert-large-uncased-whole-word-masking-tf_model.h5\n",
      "/kaggle/input/bert-tensorflow/bert-base-multilingual-uncased-config.json\n",
      "/kaggle/input/bert-tensorflow/bert-base-multilingual-cased-tf_model.h5\n",
      "/kaggle/input/bert-tensorflow/bert-base-multilingual-uncased-tf_model.h5\n",
      "/kaggle/input/bert-tensorflow/bert-base-german-cased-config.json\n",
      "/kaggle/input/bert-tensorflow/bert-base-uncased-config.json\n",
      "/kaggle/input/bert-tensorflow/bert-large-uncased-whole-word-masking-finetuned-squad-tf_model.h5\n",
      "/kaggle/input/bert-tensorflow/bert-base-uncased-tf_model.h5\n",
      "/kaggle/input/bert-tensorflow/bert-large-cased-config.json\n",
      "/kaggle/input/bert-tensorflow/bert-base-chinese-config.json\n",
      "/kaggle/input/bert-tensorflow/bert-base-german-dbmdz-uncased-config.json\n",
      "/kaggle/input/bert-tensorflow/bert-large-cased-whole-word-masking-finetuned-squad-config.json\n",
      "/kaggle/input/bert-tensorflow/bert-large-uncased-whole-word-masking-config.json\n",
      "/kaggle/input/bert-tensorflow/bert-base-cased-finetuned-mrpc-tf_model.h5\n",
      "/kaggle/input/bert-tensorflow/bert-base-german-cased-tf_model.h5\n",
      "/kaggle/input/bert-tensorflow/bert-base-multilingual-cased-config.json\n",
      "/kaggle/input/bert-tensorflow/bert-large-cased-whole-word-masking-config.json\n",
      "/kaggle/input/bert-base-from-tfhub/bert_en_uncased_L-12_H-768_A-12/saved_model.pb\n",
      "/kaggle/input/bert-base-from-tfhub/bert_en_uncased_L-12_H-768_A-12/assets/vocab.txt\n",
      "/kaggle/input/bert-base-from-tfhub/bert_en_uncased_L-12_H-768_A-12/variables/variables.data-00000-of-00001\n",
      "/kaggle/input/bert-base-from-tfhub/bert_en_uncased_L-12_H-768_A-12/variables/variables.index\n",
      "/kaggle/input/google-quest-challenge/sample_submission.csv\n",
      "/kaggle/input/google-quest-challenge/test.csv\n",
      "/kaggle/input/google-quest-challenge/train.csv\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/.appveyor.yml\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/requirements.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/.travis.yml\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/CONTRIBUTORS.md\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/README.md\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/setup.py\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/subwords.py\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/tokenize.py\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/cli.py\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/normalize.py\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/chinese.py\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/__init__.py\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/truecase.py\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/util.py\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/corpus.py\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.it\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.yue\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.pt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.de\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.lv\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.pl\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.ro\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/README.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.es\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.sl\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.fi\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.en\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.el\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.zh\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.cs\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.hu\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.is\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.ga\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.sk\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.ca\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.nl\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.ta\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.ru\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.sv\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.fr\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.lt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/Symbol.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/IsPi.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/IsAlnum-unichars-au.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/Hiragana.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/Katakana.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/Open_Punctuation.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/CJKSymbols.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/IsUpper.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/Close_Punctuation.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/IsAlpha.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/IsN.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/Hangul.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/IsPf.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/Line_Separator.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/CJK.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/IsLower.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/IsSo.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/IsAlnum.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/Number.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/IsSc.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/Lowercase_Letter.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/Hangul_Syllables.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/IsAlpha-unichars-au.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/Punctuation.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/Separator.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/Uppercase_Letter.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/Titlecase_Letter.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/Currency_Symbol.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/data/perluniprops/Han.txt\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/test/test_truecaser.py\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/test/test_corpus.py\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/test/test_normalizer.py\n",
      "/kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master/sacremoses/test/test_tokenizer.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/requirements.txt\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/MANIFEST.in\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/deploy_multi_version_doc.sh\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/.gitignore\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/LICENSE\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/CONTRIBUTING.md\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/hubconf.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/.coveragerc\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/requirements-dev.txt\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/valohai.yaml\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/README.md\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers-cli\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/setup.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/utils/link_tester.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/utils/download_glue_data.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/requirements.txt\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/README.md\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/Makefile\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/index.rst\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/bertology.rst\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/examples.md\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/migration.md\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/benchmarks.md\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/installation.md\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/multilingual.rst\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/pretrained_models.rst\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/notebooks.rst\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/model_sharing.md\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/conf.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/converting_tensorflow_models.rst\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/torchscript.rst\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/serialization.rst\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/quickstart.md\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/model_doc/camembert.rst\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/model_doc/xlnet.rst\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/model_doc/albert.rst\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/model_doc/transformerxl.rst\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/model_doc/gpt.rst\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/model_doc/gpt2.rst\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/model_doc/roberta.rst\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/model_doc/xlm.rst\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/model_doc/distilbert.rst\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/model_doc/ctrl.rst\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/model_doc/auto.rst\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/model_doc/bert.rst\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/main_classes/processors.rst\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/main_classes/configuration.rst\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/main_classes/model.rst\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/main_classes/optimizer_schedules.rst\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/main_classes/tokenizer.rst\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/imgs/warmup_constant_schedule.png\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/imgs/warmup_cosine_schedule.png\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/imgs/warmup_cosine_warm_restarts_schedule.png\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/imgs/warmup_cosine_hard_restarts_schedule.png\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/imgs/warmup_linear_schedule.png\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/imgs/transformers_logo_name.png\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/_static/css/huggingface.css\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/_static/css/Calibre-Light.ttf\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/_static/css/Calibre-Medium.otf\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/_static/css/code-snippets.css\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/_static/css/Calibre-Thin.otf\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/_static/css/Calibre-Regular.otf\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/_static/js/custom.js\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docs/source/_static/js/huggingface_logo.svg\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/docker/Dockerfile\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/templates/adding_a_new_example_script/utils_xxx.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/templates/adding_a_new_example_script/run_xxx.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/templates/adding_a_new_example_script/README.md\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/templates/adding_a_new_model/modeling_tf_xxx.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/templates/adding_a_new_model/tokenization_xxx.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/templates/adding_a_new_model/convert_xxx_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/templates/adding_a_new_model/modeling_xxx.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/templates/adding_a_new_model/README.md\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/templates/adding_a_new_model/configuration_xxx.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/templates/adding_a_new_model/tests/tokenization_xxx_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/templates/adding_a_new_model/tests/modeling_tf_xxx_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/templates/adding_a_new_model/tests/modeling_xxx_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/.circleci/config.yml\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/.circleci/deploy.sh\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/requirements.txt\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/run_generation.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/run_glue.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/run_xnli.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/utils_multiple_choice.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/utils_ner.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/run_bertology.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/run_squad.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/run_multiple_choice.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/README.md\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/test_examples.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/benchmarks.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/run_tf_ner.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/run_ner.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/run_tf_glue.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/run_lm_finetuning.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/contrib/run_openai_gpt.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/contrib/README.md\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/contrib/run_transfo_xl.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/contrib/run_swag.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/contrib/run_camembert.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/tests_samples/.gitignore\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/tests_samples/MRPC/train.tsv\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/tests_samples/MRPC/dev.tsv\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/tests_samples/SQUAD/dev-v2.0.json\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/tests_samples/SQUAD/train-v2.0.json\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/summarization/requirements.txt\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/summarization/convert_bertabs_original_pytorch_checkpoint.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/summarization/utils_summarization.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/summarization/utils_summarization_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/summarization/modeling_bertabs.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/summarization/README.md\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/summarization/run_summarization.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/summarization/configuration_bertabs.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/distillation/requirements.txt\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/distillation/grouped_batch_sampler.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/distillation/lm_seqs_dataset.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/distillation/distiller.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/distillation/train.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/distillation/README.md\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/distillation/run_squad_w_distillation.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/distillation/utils.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/distillation/scripts/extract_distilbert.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/distillation/scripts/token_counts.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/distillation/scripts/extract.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/distillation/scripts/binarized_data.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/distillation/training_configs/distilbert-base-uncased.json\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/distillation/training_configs/distilgpt2.json\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/pplm/pplm_classification_head.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/pplm/run_pplm.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/pplm/run_pplm_discrim_train.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/pplm/README.md\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/pplm/imgs/wooly.png\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/examples/pplm/imgs/headfigure.png\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/configuration_bert.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tokenization_albert.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/configuration_transfo_xl.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_bert.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_encoder_decoder.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/configuration_auto.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_albert.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_transfo_xl_utilities.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_tf_albert.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_tf_auto.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_auto.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tokenization_distilbert.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tokenization_gpt2.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_tf_openai.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/convert_t5_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tokenization_roberta.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tokenization_bert_japanese.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_tf_t5.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_t5.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/convert_roberta_original_pytorch_checkpoint_to_pytorch.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_distilbert.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_tf_gpt2.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_xlm.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/convert_transfo_xl_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tokenization_transfo_xl.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tokenization_xlnet.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_tf_roberta.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/convert_gpt2_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_tf_transfo_xl_utilities.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tokenization_camembert.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_tf_xlm.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/convert_xlm_original_pytorch_checkpoint_to_pytorch.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/configuration_xlm.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tokenization_ctrl.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/hf_api.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/convert_openai_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/optimization_tf.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/configuration_distilbert.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_ctrl.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_gpt2.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_utils.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_tf_distilbert.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/configuration_camembert.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_tf_bert.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/configuration_roberta.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/configuration_xlnet.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_openai.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/configuration_utils.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_roberta.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/__main__.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/convert_albert_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tokenization_openai.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tokenization_xlm.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tokenization_auto.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/configuration_ctrl.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/convert_pytorch_checkpoint_to_tf2.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/optimization.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/convert_xlnet_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_xlnet.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_tf_pytorch_utils.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/configuration_openai.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/convert_bert_pytorch_checkpoint_to_original_tf.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_tf_utils.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/configuration_albert.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tokenization_t5.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/convert_bert_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/__init__.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/configuration_gpt2.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_tf_transfo_xl.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/model_card.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_tf_ctrl.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/configuration_t5.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_transfo_xl.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_camembert.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tokenization_bert.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tokenization_utils.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/modeling_tf_xlnet.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/file_utils.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/data/__init__.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/data/processors/glue.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/data/processors/__init__.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/data/processors/squad.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/data/processors/utils.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/data/processors/xnli.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/data/metrics/__init__.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/data/metrics/squad_metrics.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/tokenization_bert_japanese_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/optimization_tf_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_transfo_xl_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/tokenization_auto_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/tokenization_openai_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_tf_t5_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/tokenization_tests_commons.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/tokenization_t5_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/tokenization_transfo_xl_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/hf_api_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_roberta_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/tokenization_xlnet_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_tf_gpt2_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/tokenization_distilbert_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/tokenization_utils_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_tf_auto_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_common_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/model_card_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_tf_ctrl_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/tokenization_albert_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_albert_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/tokenization_ctrl_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_tf_xlm_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/optimization_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/tokenization_xlm_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/tokenization_bert_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_tf_roberta_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_xlnet_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_gpt2_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_openai_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_tf_bert_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/tokenization_roberta_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_bert_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/__init__.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_encoder_decoder_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_t5_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/utils.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/tokenization_gpt2_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_ctrl_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_auto_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_tf_xlnet_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_distilbert_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_tf_distilbert_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_tf_common_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_tf_openai_gpt_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_tf_albert_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_tf_transfo_xl_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/modeling_xlm_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/configuration_common_test.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/fixtures/spiece.model\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/fixtures/empty.txt\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/fixtures/input.txt\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/fixtures/test_sentencepiece.model\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/tests/fixtures/sample_text.txt\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/commands/__init__.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/transformers/commands/user.py\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/notebooks/Comparing-TF-and-PT-models-SQuAD.ipynb\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/notebooks/Comparing-PT-and-TF-models.ipynb\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/notebooks/Comparing-TF-and-PT-models.ipynb\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/notebooks/Comparing-TF-and-PT-models-MLM-NSP.ipynb\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/.github/stale.yml\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/.github/ISSUE_TEMPLATE/migration.md\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/.github/ISSUE_TEMPLATE/---new-benchmark.md\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/.github/ISSUE_TEMPLATE/--new-model-addition.md\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/.github/ISSUE_TEMPLATE/feature-request.md\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/.github/ISSUE_TEMPLATE/question-help.md\n",
      "/kaggle/input/huggingface-transformers/transformers-master/transformers-master/.github/ISSUE_TEMPLATE/bug-report.md\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e3f9da6dc141f5bdfbf2ef9cf37a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import glob\n",
    "import sys\n",
    "import gc\n",
    "import os\n",
    "import re\n",
    "from math import floor, ceil\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "#TF&K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers, losses, models, callbacks\n",
    "from tensorflow.keras.initializers import *\n",
    "from tensorflow.keras.regularizers import *\n",
    "from tensorflow.keras.constraints import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "print(tf.__version__)\n",
    "\n",
    "import spacy\n",
    "from transformers import *\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "tqdm_notebook().pandas()\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train shape = (6079, 41)\n",
      "test shape = (476, 11)\n",
      "\n",
      "output categories:\n",
      "\t ['question_asker_intent_understanding', 'question_body_critical', 'question_conversational', 'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer', 'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', 'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice', 'question_type_compare', 'question_type_consequence', 'question_type_definition', 'question_type_entity', 'question_type_instructions', 'question_type_procedure', 'question_type_reason_explanation', 'question_type_spelling', 'question_well_written', 'answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance', 'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', 'answer_type_reason_explanation', 'answer_well_written']\n",
      "\n",
      "input categories:\n",
      "\t ['question_title', 'question_body', 'answer']\n"
     ]
    }
   ],
   "source": [
    "PATH = '../input/google-quest-challenge/'\n",
    "BERT_PATH = '../input/bert-base-from-tfhub/bert_en_uncased_L-12_H-768_A-12'\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_PATH+'/assets/vocab.txt', do_lower_case=True,)\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "\n",
    "df_train = pd.read_csv(PATH+'train.csv')\n",
    "df_test = pd.read_csv(PATH+'test.csv')\n",
    "df_sub = pd.read_csv(PATH+'sample_submission.csv')\n",
    "print('train shape =', df_train.shape)\n",
    "print('test shape =', df_test.shape)\n",
    "\n",
    "output_categories = list(df_train.columns[11:])\n",
    "input_categories = list(df_train.columns[[1,2,5]])\n",
    "print('\\noutput categories:\\n\\t', output_categories)\n",
    "print('\\ninput categories:\\n\\t', input_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mispell_dict = {\"aren't\" : \"are not\",          \"can't\" : \"cannot\",\n",
    "                \"couldn't\" : \"could not\",      \"couldnt\" : \"could not\",\n",
    "                \"didn't\" : \"did not\",          \"doesn't\" : \"does not\",\n",
    "                \"doesnt\" : \"does not\",         \"don't\" : \"do not\",\n",
    "                \"hadn't\" : \"had not\",          \"hasn't\" : \"has not\",\n",
    "                \"haven't\" : \"have not\",        \"havent\" : \"have not\",\n",
    "                \"he'd\" : \"he would\",           \"he'll\" : \"he will\",\n",
    "                \"he's\" : \"he is\",              \"i'd\" : \"I would\",\n",
    "                \"i'd\" : \"I had\",               \"i'll\" : \"I will\",\n",
    "                \"i'm\" : \"I am\",                \"isn't\" : \"is not\",\n",
    "                \"it's\" : \"it is\",              \"it'll\":\"it will\",\n",
    "                \"i've\" : \"I have\",             \"let's\" : \"let us\",\n",
    "                \"mightn't\" : \"might not\",      \"mustn't\" : \"must not\",\n",
    "                \"shan't\" : \"shall not\",        \"she'd\" : \"she would\",\n",
    "                \"she'll\" : \"she will\",         \"she's\" : \"she is\",\n",
    "                \"shouldn't\" : \"should not\",    \"shouldnt\" : \"should not\",\n",
    "                \"that's\" : \"that is\",          \"thats\" : \"that is\",\n",
    "                \"there's\" : \"there is\",        \"theres\" : \"there is\",\n",
    "                \"they'd\" : \"they would\",       \"they'll\" : \"they will\",\n",
    "                \"they're\" : \"they are\",        \"theyre\":  \"they are\",\n",
    "                \"they've\" : \"they have\",       \"we'd\" : \"we would\",\n",
    "                \"we're\" : \"we are\",            \"weren't\" : \"were not\",\n",
    "                \"we've\" : \"we have\",           \"what'll\" : \"what will\",\n",
    "                \"what're\" : \"what are\",        \"what's\" : \"what is\",\n",
    "                \"what've\" : \"what have\",       \"where's\" : \"where is\",\n",
    "                \"who'd\" : \"who would\",         \"who'll\" : \"who will\",\n",
    "                \"who're\" : \"who are\",          \"who's\" : \"who is\",\n",
    "                \"who've\" : \"who have\",         \"won't\" : \"will not\",\n",
    "                \"wouldn't\" : \"would not\",      \"you'd\" : \"you would\",\n",
    "                \"you'll\" : \"you will\",         \"you're\" : \"you are\",\n",
    "                \"you've\" : \"you have\",         \"'re\": \" are\",\n",
    "                \"wasn't\": \"was not\",           \"we'll\":\" will\",\n",
    "                \"didn't\": \"did not\",           \"tryin'\":\"trying\"}\n",
    "\n",
    "def _get_mispell(mispell_dict):\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    return mispell_dict, mispell_re\n",
    "\n",
    "\n",
    "def replace_typical_misspell(text):\n",
    "    mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
    "\n",
    "    def replace(match):\n",
    "        return mispellings[match.group(0)]\n",
    "\n",
    "    return mispellings_re.sub(replace, text)\n",
    "\n",
    "\n",
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&',\n",
    "          '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '',  '~', '@', '',\n",
    "          '', '_', '{', '}', '', '^', '', '`',  '<', '', '', '', '', '',\n",
    "          '', '', '', '', '', '', '', '', '', '', '', '\\xa0', '\\t',\n",
    "          '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
    "          '', '', '', '', '', '', '', '', '', '', '', '', '\\u3000', '\\u202f',\n",
    "          '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
    "          '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
    "          '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
    "          '', '', '', '', '', '', '', '', '', '', '', '', ]\n",
    "\n",
    "def clean_text(x):\n",
    "    x = str(x).replace(\"\\n\",\"\")\n",
    "    for punct in puncts:\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    return x\n",
    "\n",
    "def cln_space(x): \n",
    "    return \" \".join(x.split())\n",
    "\n",
    "def preprocess(x):\n",
    "    x= clean_text(x.lower())\n",
    "    x= replace_typical_misspell(x)\n",
    "    x= cln_space(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress-bar: 100%|| 6079/6079 [00:01<00:00, 4690.09it/s]\n",
      "progress-bar: 100%|| 6079/6079 [00:01<00:00, 4529.12it/s]\n",
      "progress-bar: 100%|| 6079/6079 [00:00<00:00, 11045.62it/s]\n",
      "progress-bar: 100%|| 476/476 [00:00<00:00, 3747.09it/s]\n",
      "progress-bar: 100%|| 476/476 [00:00<00:00, 4434.74it/s]\n",
      "progress-bar: 100%|| 476/476 [00:00<00:00, 13830.98it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train['question_body'] = df_train['question_body'].progress_map(lambda q: preprocess(q))\n",
    "df_train['answer'] = df_train['answer'].progress_map(lambda q: preprocess(q))\n",
    "df_train['question_title'] = df_train['question_title'].progress_map(lambda q: preprocess(q))\n",
    "\n",
    "df_test['question_body'] = df_test['question_body'].progress_map(lambda q: preprocess(q))\n",
    "df_test['answer'] = df_test['answer'].progress_map(lambda q: preprocess(q))\n",
    "df_test['question_title'] = df_test['question_title'].progress_map(lambda q: preprocess(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_to_transformer_inputs(title, question, answer, tokenizer, max_sequence_length):\n",
    "    \"\"\"Converts tokenized input to ids, masks and segments for transformer (including bert)\"\"\"\n",
    "    \n",
    "    def return_id(str1, str2, truncation_strategy, length):\n",
    "\n",
    "        inputs = tokenizer.encode_plus(str1, str2,\n",
    "            add_special_tokens=True,\n",
    "            max_length=length,\n",
    "            truncation_strategy=truncation_strategy)\n",
    "        \n",
    "        input_ids =  inputs[\"input_ids\"]\n",
    "        input_masks = [1] * len(input_ids)\n",
    "        input_segments = inputs[\"token_type_ids\"]\n",
    "        padding_length = length - len(input_ids)\n",
    "        padding_id = tokenizer.pad_token_id\n",
    "        input_ids = input_ids + ([padding_id] * padding_length)\n",
    "        input_masks = input_masks + ([0] * padding_length)\n",
    "        input_segments = input_segments + ([0] * padding_length)\n",
    "        \n",
    "        #print(input_ids)\n",
    "        #print(input_masks)\n",
    "\n",
    "        return [input_ids, input_masks, input_segments]\n",
    "    \n",
    "    input_ids_q, input_masks_q, input_segments_q = return_id(\n",
    "        title + ' ' + question, None, 'longest_first', max_sequence_length)\n",
    "    \n",
    "    input_ids_a, input_masks_a, input_segments_a = return_id(\n",
    "        answer, None, 'longest_first', max_sequence_length)\n",
    "    \n",
    "    return [input_ids_q, input_masks_q, input_segments_q,\n",
    "            input_ids_a, input_masks_a, input_segments_a]\n",
    "\n",
    "\n",
    "\n",
    "def compute_input_arrays(df, columns, tokenizer, max_sequence_length):\n",
    "    input_ids_q, input_masks_q, input_segments_q = [], [], []\n",
    "    input_ids_a, input_masks_a, input_segments_a = [], [], []\n",
    "    for _, instance in tqdm(df[columns].iterrows()):\n",
    "        t, q, a = instance.question_title, instance.question_body, instance.answer\n",
    "\n",
    "        ids_q, masks_q, segments_q, ids_a, masks_a, segments_a = \\\n",
    "        _convert_to_transformer_inputs(t, q, a, tokenizer, max_sequence_length)\n",
    "        \n",
    "        input_ids_q.append(ids_q)\n",
    "        input_masks_q.append(masks_q)\n",
    "        input_segments_q.append(segments_q)\n",
    "\n",
    "        input_ids_a.append(ids_a)\n",
    "        input_masks_a.append(masks_a)\n",
    "        input_segments_a.append(segments_a)\n",
    "        \n",
    "    return [np.asarray(input_ids_q, dtype=np.int32), \n",
    "            np.asarray(input_masks_q, dtype=np.int32), \n",
    "            np.asarray(input_segments_q, dtype=np.int32),\n",
    "            np.asarray(input_ids_a, dtype=np.int32), \n",
    "            np.asarray(input_masks_a, dtype=np.int32), \n",
    "            np.asarray(input_segments_a, dtype=np.int32)]\n",
    "\n",
    "def compute_output_arrays(df, columns):\n",
    "    return np.asarray(df[columns])\n",
    "\n",
    "\n",
    "def compute_spearmanr_ignore_nan(trues, preds):\n",
    "    rhos = []\n",
    "    for tcol, pcol in zip(np.transpose(trues), np.transpose(preds)):\n",
    "        rhos.append(spearmanr(tcol, pcol).correlation)\n",
    "    return np.nanmean(rhos)\n",
    "\n",
    "def compute_spearmanr(trues, preds):\n",
    "    rhos = []\n",
    "    for col_trues, col_pred in zip(trues.T, preds.T):\n",
    "        rhos.append(\n",
    "            spearmanr(col_trues, col_pred + np.random.normal(0, 1e-7, col_pred.shape[0])).correlation)\n",
    "    return np.mean(rhos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    '''\n",
    "    control learning rate\n",
    "    :param epoch:\n",
    "    :return:\n",
    "    '''\n",
    "    if epoch < 2:\n",
    "        lr = 3e-5\n",
    "    else:\n",
    "        lr = 3e-6\n",
    "    return lr\n",
    "\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay, verbose=2)\n",
    "\n",
    "keys = [0, 0.333333333333333, 0.44444444444444444, 0.55555555555555555, 0.666666666666666666666, 0.777777777777777777, 0.888888888888888888888, 1]\n",
    "def most_near(n):\n",
    "    dis = 10\n",
    "    m = 0\n",
    "    for e in keys:\n",
    "        if abs(e - n) < dis:\n",
    "            dis = abs(e - n) \n",
    "            m = e\n",
    "    # if n < 0.1:\n",
    "    #     m = 0\n",
    "    # elif n > 0.98:\n",
    "    #     m = 1\n",
    "    # else:\n",
    "    #     m = n\n",
    "    return m\n",
    "\n",
    "def repare(test_predictions):\n",
    "    result = []\n",
    "    for each in test_predictions:\n",
    "        each = each.tolist()\n",
    "        for i,t in enumerate(each):\n",
    "            temp1 = most_near(t)\n",
    "            # temp = random.randint(0,100)\n",
    "            # if temp == 10:\n",
    "            #     if temp1<0.99:\n",
    "            #         each[i] = temp1 + 0.01\n",
    "            #     else:\n",
    "            #         each[i] = temp1 - 0.01   \n",
    "            # else:\n",
    "            each[i] = temp1\n",
    "        result.append(each)\n",
    "\n",
    "    result = np.asarray(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, valid_data, test_data, batch_size=16, fold=None):\n",
    "\n",
    "        self.valid_inputs = valid_data[0]\n",
    "        self.valid_outputs = valid_data[1]\n",
    "        self.test_inputs = test_data\n",
    "        self.value = 0\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.fold = fold\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.valid_predictions = []\n",
    "        self.test_predictions = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.valid_predictions = self.model.predict(self.valid_inputs, batch_size=self.batch_size)\n",
    "        valid_predictions1 = repare(self.valid_predictions)\n",
    "        rho_val = compute_spearmanr(self.valid_outputs, self.valid_predictions)\n",
    "        print('\\nbefore repare: rho_val = {}'.format(rho_val))\n",
    "        rho_val1 = compute_spearmanr(self.valid_outputs, valid_predictions1)\n",
    "        print('after repare: rho_val = {}\\n'.format(rho_val1))\n",
    "        \n",
    "        if rho_val1 > self.value:\n",
    "            self.value = rho_val1\n",
    "            self.model.save_weights(f'/kaggle/working/Finetune-Bert-{fold}.h5')\n",
    "            \n",
    "            self.test_predictions.append(self.model.predict(self.test_inputs, batch_size=self.batch_size))\n",
    "\n",
    "            if len(self.test_predictions) > 0 :\n",
    "                self.test_predictions.pop()\n",
    "            self.test_predictions.append(self.model.predict(self.test_inputs, batch_size=self.batch_size))\n",
    "\n",
    "def create_model():\n",
    "    q_id = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    a_id = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    \n",
    "    q_mask = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    a_mask = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    \n",
    "    q_atn = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    a_atn = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    \n",
    "    config = BertConfig().from_pretrained('../input/bert-tensorflow/bert-base-uncased-config.json') # print(config) to see settings\n",
    "    config.output_hidden_states = True # Set to True to obtain hidden states\n",
    "    # caution: when using e.g. XLNet, XLNetConfig() will automatically use xlnet-large config\n",
    "    \n",
    "    # normally \".from_pretrained('bert-base-uncased')\", but because of no internet, the \n",
    "    # pretrained model has been downloaded manually and uploaded to kaggle. \n",
    "    \n",
    "    \"\"\" bert_model = TFRobertaModel.from_pretrained(\n",
    "        BERT_PATH+MODEL, config=config, from_tf=True) \"\"\"\n",
    "\n",
    "    bert_model = TFBertModel.from_pretrained(\n",
    "        pretrained_model_name_or_path='../input/bert-tensorflow/bert-base-uncased-tf_model.h5', config=config)\n",
    "\n",
    "    #bert_model = TFRobertaModel.from_pretrained(BERT_PATH+MODEL)\n",
    "\n",
    "    # if config.output_hidden_states = True, obtain hidden states via bert_model(...)[-1]\n",
    "    q_embedding, q_pooler_output, q_hidden_states = bert_model(q_id, attention_mask=q_mask, token_type_ids=q_atn)\n",
    "    a_embedding, a_pooler_output, a_hidden_states = bert_model(a_id, attention_mask=a_mask, token_type_ids=a_atn)\n",
    "\n",
    "    q_pooler_output = tf.reshape(q_pooler_output,(-1,1,768))\n",
    "    q_h12 = tf.reshape(q_hidden_states[-1][:,0],(-1,1,768))\n",
    "    q_h11 = tf.reshape(q_hidden_states[-2][:,0],(-1,1,768))\n",
    "    q_h10 = tf.reshape(q_hidden_states[-3][:,0],(-1,1,768))\n",
    "    #print(q_h10.shape)\n",
    "    #print(q_pooler_output.shape)\n",
    "    q_concat_hidden = tf.keras.layers.Concatenate(axis=2)([q_pooler_output, q_h12, q_h11, q_h10])\n",
    "    #q_concat_hidden = tf.keras.layers.Dropout(0.2)(q_concat_hidden)\n",
    "    q_x = tf.keras.layers.GlobalMaxPooling1D()(q_concat_hidden)\n",
    "\n",
    "    a_pooler_output = tf.reshape(a_pooler_output,(-1,1,768))\n",
    "    a_h12 = tf.reshape(a_hidden_states[-1][:,0],(-1,1,768))\n",
    "    a_h11 = tf.reshape(a_hidden_states[-2][:,0],(-1,1,768))\n",
    "    a_h10 = tf.reshape(a_hidden_states[-3][:,0],(-1,1,768))\n",
    "    a_concat_hidden = tf.keras.layers.Concatenate(axis=2)([a_pooler_output, a_h12, a_h11, a_h10])\n",
    "    #a_concat_hidden = tf.keras.layers.Dropout(0.2)(a_concat_hidden)\n",
    "    a_x = tf.keras.layers.GlobalMaxPooling1D()(a_concat_hidden)\n",
    "\n",
    "    concatenate_qa = tf.keras.layers.Concatenate()([q_x, a_x])\n",
    "    x = tf.keras.layers.Dropout(0.2)(concatenate_qa)\n",
    "    out = tf.keras.layers.Dense(30, activation='sigmoid')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[q_id, q_mask, q_atn, a_id, a_mask, a_atn,], outputs=out)\n",
    "    model.compile(\n",
    "        optimizer = tf.keras.optimizers.Adam(),\n",
    "        loss=['binary_crossentropy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6079it [01:33, 64.83it/s]\n",
      "476it [00:07, 63.61it/s]\n"
     ]
    }
   ],
   "source": [
    "outputs = compute_output_arrays(df_train, output_categories)\n",
    "inputs = compute_input_arrays(df_train, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n",
    "test_inputs = compute_input_arrays(df_test, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "gkf = GroupKFold(n_splits=5).split(X=df_train.question_body, groups=df_train.question_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4863 samples\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 3e-05.\n",
      "Epoch 1/3\n",
      "4862/4863 [============================>.] - ETA: 0s - loss: 0.3937\n",
      "before repare: rho_val = 0.37474672056073366\n",
      "after repare: rho_val = 0.2888690371992125\n",
      "\n",
      "4863/4863 [==============================] - 923s 190ms/sample - loss: 0.3938\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 3e-05.\n",
      "Epoch 2/3\n",
      "4862/4863 [============================>.] - ETA: 0s - loss: 0.3654\n",
      "before repare: rho_val = 0.3903010545611944\n",
      "after repare: rho_val = 0.2997348675846427\n",
      "\n",
      "4863/4863 [==============================] - 884s 182ms/sample - loss: 0.3654\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 3e-06.\n",
      "Epoch 3/3\n",
      "4862/4863 [============================>.] - ETA: 0s - loss: 0.3384\n",
      "before repare: rho_val = 0.40025503917439675\n",
      "after repare: rho_val = 0.3274254349265068\n",
      "\n",
      "4863/4863 [==============================] - 885s 182ms/sample - loss: 0.3384\n",
      "validation score =  0.400254994818915\n",
      "Train on 4863 samples\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 3e-05.\n",
      "Epoch 1/3\n",
      "4862/4863 [============================>.] - ETA: 0s - loss: 0.3935\n",
      "before repare: rho_val = 0.37372626743679405\n",
      "after repare: rho_val = 0.28708447093852274\n",
      "\n",
      "4863/4863 [==============================] - 928s 191ms/sample - loss: 0.3935\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 3e-05.\n",
      "Epoch 2/3\n",
      "4862/4863 [============================>.] - ETA: 0s - loss: 0.3647\n",
      "before repare: rho_val = 0.3866607302179946\n",
      "after repare: rho_val = 0.2892274726212866\n",
      "\n",
      "4863/4863 [==============================] - 885s 182ms/sample - loss: 0.3648\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 3e-06.\n",
      "Epoch 3/3\n",
      "4862/4863 [============================>.] - ETA: 0s - loss: 0.3393\n",
      "before repare: rho_val = 0.39943844766291964\n",
      "after repare: rho_val = 0.3145033278956472\n",
      "\n",
      "4863/4863 [==============================] - 885s 182ms/sample - loss: 0.3393\n",
      "validation score =  0.3994394758234055\n",
      "Train on 4863 samples\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 3e-05.\n",
      "Epoch 1/3\n",
      "4862/4863 [============================>.] - ETA: 0s - loss: 0.3910\n",
      "before repare: rho_val = 0.3782047795073122\n",
      "after repare: rho_val = 0.28009552298614787\n",
      "\n",
      "4863/4863 [==============================] - 926s 191ms/sample - loss: 0.3910\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 3e-05.\n",
      "Epoch 2/3\n",
      "4862/4863 [============================>.] - ETA: 0s - loss: 0.3631\n",
      "before repare: rho_val = 0.39352388385380227\n",
      "after repare: rho_val = 0.3103475543233223\n",
      "\n",
      "4863/4863 [==============================] - 880s 181ms/sample - loss: 0.3631\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 3e-06.\n",
      "Epoch 3/3\n",
      "2938/4863 [=================>............] - ETA: 5:13 - loss: 0.3375\n",
      "before repare: rho_val = 0.3993213310454239\n",
      "after repare: rho_val = 0.32268637844125225\n",
      "\n",
      "4863/4863 [==============================] - 882s 181ms/sample - loss: 0.3356\n",
      "validation score =  0.39932083937212626\n",
      "Train on 4863 samples\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 3e-05.\n",
      "Epoch 1/3\n",
      "4862/4863 [============================>.] - ETA: 0s - loss: 0.3944\n",
      "before repare: rho_val = 0.3763733278989033\n",
      "after repare: rho_val = 0.3005834807246805\n",
      "\n",
      "4863/4863 [==============================] - 922s 190ms/sample - loss: 0.3943\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 3e-05.\n",
      "Epoch 2/3\n",
      "4862/4864 [============================>.] - ETA: 0s - loss: 0.3935\n",
      "before repare: rho_val = 0.383484062111873\n",
      "after repare: rho_val = 0.2845521788463017\n",
      "\n",
      "4864/4864 [==============================] - 857s 176ms/sample - loss: 0.3935\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 3e-05.\n",
      "Epoch 2/3\n",
      "4862/4864 [============================>.] - ETA: 0s - loss: 0.3644\n",
      "before repare: rho_val = 0.3992861622095522\n",
      "after repare: rho_val = 0.2985823432206564\n",
      "\n",
      "4864/4864 [==============================] - 829s 171ms/sample - loss: 0.3644\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 3e-06.\n",
      "Epoch 3/3\n",
      "  64/4864 [..............................] - ETA: 12:07 - loss: 0.3655"
     ]
    }
   ],
   "source": [
    "valid_preds = []\n",
    "test_preds = []\n",
    "valss = []\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
    "    \n",
    "    if fold < 6:\n",
    "        train_inputs = [inputs[i][train_idx] for i in range(len(inputs))]\n",
    "        train_outputs = outputs[train_idx]\n",
    "    \n",
    "        valid_inputs = [inputs[i][valid_idx] for i in range(len(inputs))]\n",
    "        valid_outputs = outputs[valid_idx]\n",
    "    \n",
    "        custom_callback = CustomCallback(\n",
    "            valid_data=(valid_inputs, valid_outputs), \n",
    "            test_data=test_inputs,\n",
    "            batch_size=16,\n",
    "            fold=fold)\n",
    "        \n",
    "        K.clear_session()\n",
    "        model = create_model()\n",
    "        model.fit(train_inputs, train_outputs, epochs=3, batch_size=2, callbacks=[custom_callback, lrate])\n",
    "        #model.save_weights('FinetuneRoberta'+ str(fold) + '.h5')\n",
    "        valid_preds.append(model.predict(valid_inputs))\n",
    "        test_preds.append(model.predict(test_inputs))\n",
    "        \n",
    "        rho_val = compute_spearmanr_ignore_nan(valid_outputs, valid_preds[-1])\n",
    "        print('validation score = ', rho_val)\n",
    "        valss.append(rho_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local cv = 0.39968045159451243\n"
     ]
    }
   ],
   "source": [
    "df_sub.iloc[:, 1:] = np.average(test_preds, axis=0) # for weighted average set weights=[...]\n",
    "df_sub.to_csv('submission.csv', index=False)\n",
    "print('local cv = {}'.format(np.array(valss).mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "18e3f9da6dc141f5bdfbf2ef9cf37a09": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d022a88725b440f797270cc2423302ac",
        "IPY_MODEL_90f2e0a14ed146328da97108e8f24ebc"
       ],
       "layout": "IPY_MODEL_7659a28ddb794f1386f1c146f160d5e8"
      }
     },
     "38fe7fd435b941ebb856f974ea378472": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "4b3e49538bfc4b67a4640cda7fffa78f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7659a28ddb794f1386f1c146f160d5e8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "90f2e0a14ed146328da97108e8f24ebc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4b3e49538bfc4b67a4640cda7fffa78f",
       "placeholder": "",
       "style": "IPY_MODEL_b89b83d391854d29ba562ee54e981a59",
       "value": " 0/? [00:00&lt;?, ?it/s]"
      }
     },
     "b89b83d391854d29ba562ee54e981a59": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c6d83e0307ae42ad92a606af4d721743": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d022a88725b440f797270cc2423302ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c6d83e0307ae42ad92a606af4d721743",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_38fe7fd435b941ebb856f974ea378472",
       "value": 0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
